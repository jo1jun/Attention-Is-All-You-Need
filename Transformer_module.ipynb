{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer_module.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1KvH4Tc4UzR5YryjjzgjJL5JxiDBi-mjb",
      "authorship_tag": "ABX9TyOWAhWn6ksCuv8hNlYf3SKq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jo1jun/Transformer/blob/main/Transformer_module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYBSRl95FuQM"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR_upKGm3aWx"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "dtype = torch.long"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf7LgzJyGSJ-"
      },
      "source": [
        "# Token & Positional Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnK60PP6w1nr"
      },
      "source": [
        "class TokPosEmbedding(nn.Module):\n",
        "  def __init__(self, input_dim, d_model, dropout_ratio):\n",
        "    super().__init__()\n",
        "    self.tokEmbedding = nn.Embedding(input_dim, d_model)\n",
        "    self.posEmbedding = nn.Embedding(input_dim, d_model) # 위치 임베딩을 고정 함수가 아니라 학습하는 형태로 구현.\n",
        "    self.d_model = d_model\n",
        "    self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "  def forward(self, src):\n",
        "    batch_size = src.shape[0]\n",
        "    src_len = src.shape[1]\n",
        "\n",
        "    pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(device) # 0 ~ src_len 등차 수열값 을 bactch 한개와 동일한 shape으로 생성\n",
        "    \n",
        "    # pos: [batch_size, src_len]\n",
        "\n",
        "    src = self.dropout((self.tokEmbedding(src) * np.sqrt(self.d_model)) + self.posEmbedding(pos))\n",
        "\n",
        "    # src: [batch_size, src_len, d_model]\n",
        "\n",
        "    return src"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72qVz_GlGnIK"
      },
      "source": [
        "# Transformer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx_loYBXxoG7"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, d_model, n_layers, nhead, ff_dim, dropout_ratio):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encEmbedding = TokPosEmbedding(input_dim, d_model, dropout_ratio)                # 외부에서 embedding\n",
        "        self.encoderLayer = nn.TransformerEncoderLayer(d_model, nhead, ff_dim, dropout_ratio) # 구현되어있는 module 사용\n",
        "        self.encoder = nn.TransformerEncoder(self.encoderLayer, n_layers)                     # 구현되어있는 module 사용\n",
        "        self.decEmbedding = TokPosEmbedding(output_dim, d_model, dropout_ratio)               # 외부에서 embedding\n",
        "        self.decoderLayer = nn.TransformerDecoderLayer(d_model, nhead, ff_dim, dropout_ratio) # 구현되어있는 module 사용\n",
        "        self.decoder = nn.TransformerDecoder(self.decoderLayer, n_layers)                     # 구현되어있는 module 사용\n",
        "        self.linear = nn.Linear(d_model, output_dim)                                          # 외부에서 마지막 fc-layer\n",
        "\n",
        "    def make_pad_mask(self, src, pad):\n",
        "\n",
        "        # src: [batch_size, src_len]\n",
        "\n",
        "        # pad mask\n",
        "        src_mask = (src.data.eq(pad))\n",
        "\n",
        "        # src_mask: [batch_size, src_len]\n",
        "        return src_mask\n",
        "\n",
        "    def forward(self, src, tgt, pad):\n",
        "        \n",
        "        # src: [batch_size, src_len]\n",
        "        # tgt: [batch_size, tgt_len]\n",
        "\n",
        "        src_pad_mask = self.make_pad_mask(src, pad)\n",
        "        tgt_pad_mask = self.make_pad_mask(tgt, pad)\n",
        "        # chitting 방지 mask 의 경우, 아래와 같이 이미 구현되어있다. 기존과 mask 값이 다르므로 이미 구현된 것을 사용하면 된다.\n",
        "        tgt_sub_mask = nn.Transformer.generate_square_subsequent_mask(self, sz=tgt.shape[1]).to(device)\n",
        "\n",
        "        # src_pad_mask: [batch_size, src_len]\n",
        "        # tgt_pad_mask: [batch_size, tgt_len]\n",
        "        # tgt_sub_mask: [tgt_len, tgt_len]\n",
        "\n",
        "        src = self.encEmbedding(src)\n",
        "        tgt = self.decEmbedding(tgt)\n",
        "\n",
        "        # 기존과 달리 input, output 의 dim 0, 1 이 바뀌어 있다.\n",
        "        enc_src = self.encoder(src.transpose(0,1), src_key_padding_mask=src_pad_mask) \n",
        "\n",
        "        # enc_src: [src_len, batch_size, d_model]\n",
        "\n",
        "        output = self.decoder(tgt.transpose(0,1), enc_src, tgt_sub_mask, None, tgt_pad_mask, src_pad_mask)\n",
        "\n",
        "        # output: [tgt_len, batch_size, d_model]\n",
        "\n",
        "        output = self.linear(output.transpose(0, 1))\n",
        "\n",
        "        # output: [batch_size, tgt_len, output_dim]\n",
        "\n",
        "        return output\n",
        "\n",
        "    def generate(self, src, start_id, sample_size, pad):\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "\n",
        "        src_pad_mask = self.make_pad_mask(src, pad)\n",
        "\n",
        "        src = self.encEmbedding(src)\n",
        "\n",
        "        enc_src = self.encoder(src.transpose(0,1), src_key_padding_mask=src_pad_mask)\n",
        "      \n",
        "        sampled_tensor = torch.tensor([start_id], dtype=dtype).unsqueeze(0).repeat(batch_size, 1).to(device)\n",
        "        for _ in range(sample_size):\n",
        "\n",
        "          tgt_pad_mask = self.make_pad_mask(sampled_tensor, pad)\n",
        "          tgt = self.decEmbedding(sampled_tensor)\n",
        "          \n",
        "          # generate 할 때는 하나씩 단어를 생성하므로 tgt_sub_mask 의미 x\n",
        "          output = self.decoder(tgt.transpose(0,1), enc_src, None, None, tgt_pad_mask, src_pad_mask)\n",
        "          output = self.linear(output.transpose(0,1))\n",
        "\n",
        "          pred_token = output.argmax(2)[:,-1].unsqueeze(1)\n",
        "\n",
        "          sampled_tensor = torch.cat((sampled_tensor, pred_token), 1) # pred sentence 에 concat\n",
        "\n",
        "        return sampled_tensor"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1Wt3T1sIOLw"
      },
      "source": [
        "# Date format Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31OPk52Y2DOS",
        "outputId": "bb8b494c-63fe-4e36-96b8-061a3e2b0f1b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTmbqE0665fq",
        "outputId": "0cc2f1bd-da64-48b4-f435-b78e2f5c7ab1"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/dataset')\n",
        "import sequence\n",
        "\n",
        "# google mount 한 뒤 '/content/drive/MyDrive/' 에 dataset 저장 후 실행.\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = sequence.load_data('date.txt')\n",
        "# char -> id & id -> char dictionary\n",
        "char_to_id, id_to_char = sequence.get_vocab()\n",
        "\n",
        "print(x_train.shape)\n",
        "print(t_train.shape)\n",
        "print(x_test.shape)\n",
        "print(t_test.shape)\n",
        "print()\n",
        "\n",
        "# 이미 id 화 되어있다.\n",
        "print('question(id) : ', x_train[0])\n",
        "print('correct(id)  : ',t_train[0])\n",
        "print()\n",
        "\n",
        "# sequence 확인 # ' ' : pad, '_' : start_char\n",
        "print('question(char) : ', ' '.join([id_to_char[int(c)] for c in x_train[0]]))\n",
        "print('correct(char)  : ', ' '.join([id_to_char[int(c)] for c in t_train[0]]))\n",
        "\n",
        "vocab_size = len(char_to_id)\n",
        "x_train = torch.tensor(x_train, dtype=dtype)\n",
        "t_train = torch.tensor(t_train, dtype=dtype)\n",
        "x_test = torch.tensor(x_test, dtype=dtype)\n",
        "t_test = torch.tensor(t_test, dtype=dtype)\n",
        "pad = 7 # pad token"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(45000, 29)\n",
            "(45000, 11)\n",
            "(5000, 29)\n",
            "(5000, 11)\n",
            "\n",
            "question(id) :  [ 8 22  9 22  9  8  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
            "  7  7  7  7  7]\n",
            "correct(id)  :  [14 11 12  9  8 15 16  8 15 16  9]\n",
            "\n",
            "question(char) :  2 / 7 / 7 2                                              \n",
            "correct(char)  :  _ 1 9 7 2 - 0 2 - 0 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRwkTDN0IQKk"
      },
      "source": [
        "# hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISwDWr4C5djP"
      },
      "source": [
        "batch_size = 128\n",
        "epoch = 20\n",
        "input_dim = output_dim = vocab_size\n",
        "d_model = 32\n",
        "n_layers = 1\n",
        "nhead = 2\n",
        "ff_dim = 1024\n",
        "dropout_ratio = 0.1\n",
        "learning_rate = 0.0025"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9nRECFb-Otd"
      },
      "source": [
        "model = Transformer(input_dim, output_dim, d_model, n_layers, nhead, ff_dim, dropout_ratio)"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqnMGy1W2LbR"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v41wbzYFVtcI"
      },
      "source": [
        "# Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMLAnqwZVv8j"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "loader_x_train = DataLoader(x_train, batch_size=batch_size)\n",
        "loader_t_train = DataLoader(t_train, batch_size=batch_size)\n",
        "loader_x_test = DataLoader(x_test, batch_size=batch_size)\n",
        "loader_t_test = DataLoader(t_test, batch_size=batch_size)"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7OpyjK1ITeB"
      },
      "source": [
        "# Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ILurmyh97dA"
      },
      "source": [
        "def trainer(model, optimizer, epochs, pad):\n",
        "\n",
        "    pad = torch.tensor([pad], dtype=dtype).to(device)\n",
        "\n",
        "    model.train()\n",
        "    model = model.to(device)\n",
        "    for e in range(epochs):\n",
        "        for iters, (batch_x, batch_t) in enumerate(zip(loader_x_train, loader_t_train)):\n",
        "\n",
        "            batch_x = batch_x.to(device)\n",
        "            batch_t = batch_t.to(device)\n",
        "\n",
        "            # correct 값의 마지막 원소 배제 (end token 없음. 마지막 원소 다음 token 학습할 필요 x)\n",
        "            scores = model(batch_x, batch_t[:, :-1], pad)\n",
        "\n",
        "            scores_dim = scores.shape[-1]\n",
        "\n",
        "            scores = scores.reshape(-1, scores_dim)\n",
        "            \n",
        "            # correct 값의 첫 원소 배제\n",
        "            batch_t = batch_t[:, 1:].reshape(-1)\n",
        "\n",
        "            # scores  : [batch_size * tgt_len - 1, output_dim]\n",
        "            # batch_t : [batch_size * tgt_len - 1]\n",
        "\n",
        "            loss = criterion(scores, batch_t)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0) # gradient clippling\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            if iters % 100 == 0:\n",
        "                print('epoch[%d/%d] loss = %.4f' % (e+1, epochs, loss.item()))"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZyw77ZvIUUb"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGHsfmXo2N23",
        "outputId": "295a38f3-9bd7-4d45-a2b7-56d06af0a9bc"
      },
      "source": [
        "trainer(model, optimizer, epoch, pad)"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch[1/20] loss = 4.1975\n",
            "epoch[1/20] loss = 0.9225\n",
            "epoch[1/20] loss = 0.6719\n",
            "epoch[1/20] loss = 0.4677\n",
            "epoch[2/20] loss = 0.4553\n",
            "epoch[2/20] loss = 0.3535\n",
            "epoch[2/20] loss = 0.3090\n",
            "epoch[2/20] loss = 0.2387\n",
            "epoch[3/20] loss = 0.2068\n",
            "epoch[3/20] loss = 0.1780\n",
            "epoch[3/20] loss = 0.1821\n",
            "epoch[3/20] loss = 0.1507\n",
            "epoch[4/20] loss = 0.1215\n",
            "epoch[4/20] loss = 0.1343\n",
            "epoch[4/20] loss = 0.1033\n",
            "epoch[4/20] loss = 0.1090\n",
            "epoch[5/20] loss = 0.1109\n",
            "epoch[5/20] loss = 0.1142\n",
            "epoch[5/20] loss = 0.0960\n",
            "epoch[5/20] loss = 0.0973\n",
            "epoch[6/20] loss = 0.0800\n",
            "epoch[6/20] loss = 0.0745\n",
            "epoch[6/20] loss = 0.0925\n",
            "epoch[6/20] loss = 0.0864\n",
            "epoch[7/20] loss = 0.0715\n",
            "epoch[7/20] loss = 0.0611\n",
            "epoch[7/20] loss = 0.0766\n",
            "epoch[7/20] loss = 0.0613\n",
            "epoch[8/20] loss = 0.0735\n",
            "epoch[8/20] loss = 0.0453\n",
            "epoch[8/20] loss = 0.0593\n",
            "epoch[8/20] loss = 0.0725\n",
            "epoch[9/20] loss = 0.0673\n",
            "epoch[9/20] loss = 0.0692\n",
            "epoch[9/20] loss = 0.0605\n",
            "epoch[9/20] loss = 0.0614\n",
            "epoch[10/20] loss = 0.0544\n",
            "epoch[10/20] loss = 0.0609\n",
            "epoch[10/20] loss = 0.0670\n",
            "epoch[10/20] loss = 0.0523\n",
            "epoch[11/20] loss = 0.0415\n",
            "epoch[11/20] loss = 0.0534\n",
            "epoch[11/20] loss = 0.0510\n",
            "epoch[11/20] loss = 0.0519\n",
            "epoch[12/20] loss = 0.0548\n",
            "epoch[12/20] loss = 0.0600\n",
            "epoch[12/20] loss = 0.0638\n",
            "epoch[12/20] loss = 0.0446\n",
            "epoch[13/20] loss = 0.0339\n",
            "epoch[13/20] loss = 0.0450\n",
            "epoch[13/20] loss = 0.0394\n",
            "epoch[13/20] loss = 0.0353\n",
            "epoch[14/20] loss = 0.0385\n",
            "epoch[14/20] loss = 0.0366\n",
            "epoch[14/20] loss = 0.0393\n",
            "epoch[14/20] loss = 0.0466\n",
            "epoch[15/20] loss = 0.0393\n",
            "epoch[15/20] loss = 0.0478\n",
            "epoch[15/20] loss = 0.0523\n",
            "epoch[15/20] loss = 0.0605\n",
            "epoch[16/20] loss = 0.0401\n",
            "epoch[16/20] loss = 0.0503\n",
            "epoch[16/20] loss = 0.0255\n",
            "epoch[16/20] loss = 0.0395\n",
            "epoch[17/20] loss = 0.0284\n",
            "epoch[17/20] loss = 0.0412\n",
            "epoch[17/20] loss = 0.0417\n",
            "epoch[17/20] loss = 0.0455\n",
            "epoch[18/20] loss = 0.0257\n",
            "epoch[18/20] loss = 0.0351\n",
            "epoch[18/20] loss = 0.0452\n",
            "epoch[18/20] loss = 0.0343\n",
            "epoch[19/20] loss = 0.0350\n",
            "epoch[19/20] loss = 0.0334\n",
            "epoch[19/20] loss = 0.0417\n",
            "epoch[19/20] loss = 0.0289\n",
            "epoch[20/20] loss = 0.0271\n",
            "epoch[20/20] loss = 0.0329\n",
            "epoch[20/20] loss = 0.0486\n",
            "epoch[20/20] loss = 0.0310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND8712XqIWLj"
      },
      "source": [
        "# Checker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2MGYo8OkDXd"
      },
      "source": [
        "def checker(loader_x, loader_t, model, pad):\n",
        "\n",
        "    pad = torch.tensor([pad], dtype=dtype).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      correct_num = 0\n",
        "      for iters, (batch_x, batch_t) in enumerate(zip(loader_x, loader_t)):\n",
        "\n",
        "        batch_x = batch_x.to(device)\n",
        "        batch_t = batch_t.to(device)\n",
        "\n",
        "        start_id = batch_t[0,0]\n",
        "        correct = batch_t[:,1:]\n",
        "\n",
        "        predict = model.generate(batch_x, start_id, correct.shape[1], pad)\n",
        "        predict = predict[:,1:]\n",
        "\n",
        "        correct_num += (predict == correct).sum()\n",
        "        \n",
        "    return correct_num"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VCFvSrXIYzb"
      },
      "source": [
        "# Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HpiowyN2Rfk",
        "outputId": "55a0650e-8504-410d-83f9-e6a70d4c13a5"
      },
      "source": [
        "correct_num = checker(loader_x_train, loader_t_train, model, pad)\n",
        "acc = float(correct_num) / (t_train.shape[0] * (t_train.shape[1] - 1))\n",
        "print('train accuracy %.3f%%' % (acc * 100))\n",
        "\n",
        "correct_num = checker(loader_x_test, loader_t_test,model, pad)\n",
        "acc = float(correct_num) / (t_test.shape[0] * (t_test.shape[1] - 1))\n",
        "print('test accuracy %.3f%%' % (acc * 100))"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train accuracy 99.423%\n",
            "test accuracy 99.478%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-uBPml1IbM9"
      },
      "source": [
        "# Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgvyoX6mCUGv",
        "outputId": "9dbc7885-1aa9-4c09-e1ca-19d2dff58217"
      },
      "source": [
        "for i in range(10):\n",
        "  idx = [i]\n",
        "\n",
        "  question = x_test[idx].to(device)\n",
        "  correct = t_test[idx].to(device)\n",
        "  pad = torch.tensor([pad], dtype=dtype).to(device)\n",
        "\n",
        "  correct = correct.flatten()\n",
        "  # 머릿글자\n",
        "  start_id = correct[0]\n",
        "\n",
        "  correct = correct[1:]\n",
        "  with torch.no_grad():\n",
        "    predict  = model.generate(question, start_id, len(correct), pad)\n",
        "  predict = predict[:,1:]\n",
        "\n",
        "  # 문자열로 변환\n",
        "  question = [id_to_char[int(c)] for c in question.flatten()]\n",
        "  correct = [id_to_char[int(c)] for c in correct.flatten()]\n",
        "  predict = [id_to_char[int(c)] for c in predict.flatten()]\n",
        "\n",
        "  print(f'question {i+1} : ', ' '.join(question))\n",
        "  print(f'correct {i+1}  : ', ' '.join(correct))\n",
        "  print(f'predict {i+1}  : ', ' '.join(predict))\n",
        "  print()"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "question 1 :  1 0 / 1 5 / 9 4                                          \n",
            "correct 1  :  1 9 9 4 - 1 0 - 1 5\n",
            "predict 1  :  1 9 9 4 - 1 0 - 1 5\n",
            "\n",
            "question 2 :  t h u r s d a y ,   n o v e m b e r   1 3 ,   2 0 0 8    \n",
            "correct 2  :  2 0 0 8 - 1 1 - 1 3\n",
            "predict 2  :  2 0 0 8 - 1 1 - 1 3\n",
            "\n",
            "question 3 :  M a r   2 5 ,   2 0 0 3                                  \n",
            "correct 3  :  2 0 0 3 - 0 3 - 2 5\n",
            "predict 3  :  2 0 0 3 - 0 3 - 2 5\n",
            "\n",
            "question 4 :  T u e s d a y ,   N o v e m b e r   2 2 ,   2 0 1 6      \n",
            "correct 4  :  2 0 1 6 - 1 1 - 2 2\n",
            "predict 4  :  2 0 1 6 - 1 1 - 2 2\n",
            "\n",
            "question 5 :  S a t u r d a y ,   J u l y   1 8 ,   1 9 7 0            \n",
            "correct 5  :  1 9 7 0 - 0 7 - 1 8\n",
            "predict 5  :  1 9 7 0 - 0 7 - 1 8\n",
            "\n",
            "question 6 :  o c t o b e r   6 ,   1 9 9 2                            \n",
            "correct 6  :  1 9 9 2 - 1 0 - 0 6\n",
            "predict 6  :  1 9 9 2 - 1 0 - 0 6\n",
            "\n",
            "question 7 :  8 / 2 3 / 0 8                                            \n",
            "correct 7  :  2 0 0 8 - 0 8 - 2 3\n",
            "predict 7  :  2 0 0 8 - 0 8 - 2 3\n",
            "\n",
            "question 8 :  8 / 3 0 / 0 7                                            \n",
            "correct 8  :  2 0 0 7 - 0 8 - 3 0\n",
            "predict 8  :  2 0 0 7 - 0 8 - 3 0\n",
            "\n",
            "question 9 :  1 0 / 2 8 / 1 3                                          \n",
            "correct 9  :  2 0 1 3 - 1 0 - 2 8\n",
            "predict 9  :  2 0 1 3 - 1 0 - 2 8\n",
            "\n",
            "question 10 :  s u n d a y ,   n o v e m b e r   6 ,   2 0 1 6          \n",
            "correct 10  :  2 0 1 6 - 1 1 - 0 6\n",
            "predict 10  :  2 0 1 6 - 1 1 - 0 6\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}