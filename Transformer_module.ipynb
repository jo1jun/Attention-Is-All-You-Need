{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer_module.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1KvH4Tc4UzR5YryjjzgjJL5JxiDBi-mjb",
      "authorship_tag": "ABX9TyPV6NXC23Ym0FsfemXCCRYk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jo1jun/Transformer/blob/main/Transformer_module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYBSRl95FuQM"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR_upKGm3aWx"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 기존과 달리 device, dtype 전부 떼어내야 작동. 추측컨데, 내부적으로 구현이 되어있는 듯 하다.\n",
        "# document 에 parameter 에 device 를 받는다고 나와있는데 바뀐듯 하다. 학습속도가 기존보다 느린데 알아보자.\n",
        "# TODO : device 관련 내부 구현 여부 확인"
      ],
      "execution_count": 721,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf7LgzJyGSJ-"
      },
      "source": [
        "# Token & Positional Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnK60PP6w1nr"
      },
      "source": [
        "class TokPosEmbedding(nn.Module):\n",
        "  def __init__(self, input_dim, d_model, dropout_ratio):\n",
        "    super().__init__()\n",
        "    self.tokEmbedding = nn.Embedding(input_dim, d_model)\n",
        "    self.posEmbedding = nn.Embedding(input_dim, d_model) # 위치 임베딩을 고정 함수가 아니라 학습하는 형태로 구현.\n",
        "    self.d_model = d_model\n",
        "    self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "  def forward(self, src):\n",
        "    batch_size = src.shape[0]\n",
        "    src_len = src.shape[1]\n",
        "\n",
        "    pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1) # 0 ~ src_len 등차 수열값 을 bactch 한개와 동일한 shape으로 생성\n",
        "    \n",
        "    # pos: [batch_size, src_len]\n",
        "\n",
        "    src = self.dropout((self.tokEmbedding(src) * np.sqrt(self.d_model)) + self.posEmbedding(pos))\n",
        "\n",
        "    # src: [batch_size, src_len, d_model]\n",
        "\n",
        "    return src"
      ],
      "execution_count": 722,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72qVz_GlGnIK"
      },
      "source": [
        "# Transformer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx_loYBXxoG7"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, d_model, n_layers, nhead, ff_dim, dropout_ratio):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encEmbedding = TokPosEmbedding(input_dim, d_model, dropout_ratio)                # 외부에서 embedding\n",
        "        self.encoderLayer = nn.TransformerEncoderLayer(d_model, nhead, ff_dim, dropout_ratio) # 구현되어있는 module 사용\n",
        "        self.encoder = nn.TransformerEncoder(self.encoderLayer, n_layers)                     # 구현되어있는 module 사용\n",
        "        self.decEmbedding = TokPosEmbedding(output_dim, d_model, dropout_ratio)               # 외부에서 embedding\n",
        "        self.decoderLayer = nn.TransformerDecoderLayer(d_model, nhead, ff_dim, dropout_ratio) # 구현되어있는 module 사용\n",
        "        self.decoder = nn.TransformerDecoder(self.decoderLayer, n_layers)                     # 구현되어있는 module 사용\n",
        "        self.linear = nn.Linear(d_model, output_dim)                                          # 외부에서 마지막 fc-layer\n",
        "\n",
        "    def make_pad_mask(self, src, pad):\n",
        "\n",
        "        # src: [batch_size, src_len]\n",
        "\n",
        "        # pad mask\n",
        "        src_mask = (src.data.eq(pad))\n",
        "\n",
        "        # src_mask: [batch_size, src_len]\n",
        "        return src_mask\n",
        "\n",
        "    def forward(self, src, tgt, pad):\n",
        "        \n",
        "        # src: [batch_size, src_len]\n",
        "        # tgt: [batch_size, tgt_len]\n",
        "\n",
        "        src_pad_mask = self.make_pad_mask(src, pad)\n",
        "        tgt_pad_mask = self.make_pad_mask(tgt, pad)\n",
        "        # chitting 방지 mask 의 경우, 아래와 같이 이미 구현되어있다. 기존과 mask 값이 다르므로 이미 구현된 것을 사용하면 된다.\n",
        "        tgt_sub_mask = nn.Transformer.generate_square_subsequent_mask(self, sz=tgt.shape[1])\n",
        "\n",
        "        # src_pad_mask: [batch_size, src_len]\n",
        "        # tgt_pad_mask: [batch_size, tgt_len]\n",
        "        # tgt_sub_mask: [tgt_len, tgt_len]\n",
        "\n",
        "        src = self.encEmbedding(src)\n",
        "        tgt = self.decEmbedding(tgt)\n",
        "\n",
        "        # 기존과 달리 input, output 의 dim 0, 1 이 바뀌어 있다.\n",
        "        enc_src = self.encoder(src.transpose(0,1), src_key_padding_mask=src_pad_mask) \n",
        "\n",
        "        # enc_src: [src_len, batch_size, d_model]\n",
        "\n",
        "        output = self.decoder(tgt.transpose(0,1), enc_src, tgt_sub_mask, None, tgt_pad_mask, src_pad_mask)\n",
        "\n",
        "        # output: [tgt_len, batch_size, d_model]\n",
        "\n",
        "        output = self.linear(output.transpose(0, 1))\n",
        "\n",
        "        # output: [batch_size, tgt_len, output_dim]\n",
        "\n",
        "        return output\n",
        "\n",
        "    def generate(self, src, start_id, sample_size, pad):\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "\n",
        "        src_pad_mask = self.make_pad_mask(src, pad)\n",
        "\n",
        "        src = self.encEmbedding(src)\n",
        "\n",
        "        enc_src = self.encoder(src.transpose(0,1), src_key_padding_mask=src_pad_mask)\n",
        "      \n",
        "        sampled_tensor = torch.LongTensor([start_id]).unsqueeze(0).repeat(batch_size, 1)\n",
        "        for _ in range(sample_size):\n",
        "\n",
        "          tgt_pad_mask = self.make_pad_mask(sampled_tensor, pad)\n",
        "          tgt = self.decEmbedding(sampled_tensor)\n",
        "          \n",
        "          output = self.decoder(tgt.transpose(0,1), enc_src, None, None, tgt_pad_mask, src_pad_mask)\n",
        "          output = self.linear(output.transpose(0,1))\n",
        "\n",
        "          pred_token = output.argmax(2)[:,-1].unsqueeze(1)\n",
        "\n",
        "          sampled_tensor = torch.cat((sampled_tensor, pred_token), 1) # pred sentence 에 concat\n",
        "\n",
        "        return sampled_tensor"
      ],
      "execution_count": 723,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1Wt3T1sIOLw"
      },
      "source": [
        "# Date format Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31OPk52Y2DOS",
        "outputId": "82f39f38-2044-4f6c-e0ad-686321c5d84b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 724,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTmbqE0665fq",
        "outputId": "f64b8974-ba15-461f-c0c0-358a544ab7df"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/dataset')\n",
        "import sequence\n",
        "\n",
        "# google mount 한 뒤 '/content/drive/MyDrive/' 에 dataset 저장 후 실행.\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = sequence.load_data('date.txt')\n",
        "# char -> id & id -> char dictionary\n",
        "char_to_id, id_to_char = sequence.get_vocab()\n",
        "\n",
        "print(x_train.shape)\n",
        "print(t_train.shape)\n",
        "print(x_test.shape)\n",
        "print(t_test.shape)\n",
        "print()\n",
        "\n",
        "# 이미 id 화 되어있다.\n",
        "print('question(id) : ', x_train[0])\n",
        "print('correct(id)  : ',t_train[0])\n",
        "print()\n",
        "\n",
        "# sequence 확인 # ' ' : pad, '_' : start_char\n",
        "print('question(char) : ', ' '.join([id_to_char[int(c)] for c in x_train[0]]))\n",
        "print('correct(char)  : ', ' '.join([id_to_char[int(c)] for c in t_train[0]]))\n",
        "\n",
        "vocab_size = len(char_to_id)\n",
        "x_train = torch.LongTensor(x_train)\n",
        "t_train = torch.LongTensor(t_train)\n",
        "x_test = torch.LongTensor(x_test)\n",
        "t_test = torch.LongTensor(t_test)\n",
        "pad = 7 # pad token"
      ],
      "execution_count": 725,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(45000, 29)\n",
            "(45000, 11)\n",
            "(5000, 29)\n",
            "(5000, 11)\n",
            "\n",
            "question(id) :  [ 8 22  9 22  9  8  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
            "  7  7  7  7  7]\n",
            "correct(id)  :  [14 11 12  9  8 15 16  8 15 16  9]\n",
            "\n",
            "question(char) :  2 / 7 / 7 2                                              \n",
            "correct(char)  :  _ 1 9 7 2 - 0 2 - 0 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRwkTDN0IQKk"
      },
      "source": [
        "# hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISwDWr4C5djP"
      },
      "source": [
        "batch_size = 128\n",
        "epoch = 10\n",
        "input_dim = output_dim = vocab_size\n",
        "d_model = 32\n",
        "n_layers = 1\n",
        "nhead = 2\n",
        "ff_dim = 1024\n",
        "dropout_ratio = 0.1\n",
        "learning_rate = 0.0025"
      ],
      "execution_count": 726,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9nRECFb-Otd"
      },
      "source": [
        "model = Transformer(input_dim, output_dim, d_model, n_layers, nhead, ff_dim, dropout_ratio)"
      ],
      "execution_count": 727,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqnMGy1W2LbR"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 728,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7OpyjK1ITeB"
      },
      "source": [
        "# Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ILurmyh97dA"
      },
      "source": [
        "def trainer(x, t, max_epoch, batch_size, model, optimizer, pad):\n",
        "\n",
        "    data_size = len(x)\n",
        "    max_iters = data_size // batch_size\n",
        "    pad = torch.LongTensor([pad])\n",
        "\n",
        "    model.train()\n",
        "    for e in range(max_epoch):\n",
        "        for iters in range(max_iters):\n",
        "            batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
        "            batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
        "\n",
        "            # correct 값의 마지막 원소 배제 (end token 없음. 마지막 원소 다음 token 학습할 필요 x)\n",
        "            scores = model(batch_x, batch_t[:, :-1], pad)\n",
        "\n",
        "            scores_dim = scores.shape[-1]\n",
        "\n",
        "            scores = scores.reshape(-1, scores_dim)\n",
        "            \n",
        "            # correct 값의 첫 원소 배제\n",
        "            batch_t = batch_t[:, 1:].reshape(-1)\n",
        "\n",
        "            # scores  : [batch_size * tgt_len - 1, output_dim]\n",
        "            # batch_t : [batch_size * tgt_len - 1]\n",
        "\n",
        "            loss = criterion(scores, batch_t)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0) # gradient clippling\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            if iters % 100 == 0:\n",
        "                print('epoch[%d/%d] Iteration %d/%d, loss = %.4f' % (e+1, max_epoch, iters, max_iters, loss.item()))"
      ],
      "execution_count": 729,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZyw77ZvIUUb"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGHsfmXo2N23",
        "outputId": "0c27ee35-0a0f-4586-a338-a0e792735974"
      },
      "source": [
        "trainer(x_train, t_train, epoch, batch_size, model, optimizer, pad)"
      ],
      "execution_count": 730,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch[1/10] Iteration 0/351, loss = 3.9641\n",
            "epoch[1/10] Iteration 100/351, loss = 0.9319\n",
            "epoch[1/10] Iteration 200/351, loss = 0.7200\n",
            "epoch[1/10] Iteration 300/351, loss = 0.4947\n",
            "epoch[2/10] Iteration 0/351, loss = 0.4112\n",
            "epoch[2/10] Iteration 100/351, loss = 0.3152\n",
            "epoch[2/10] Iteration 200/351, loss = 0.2690\n",
            "epoch[2/10] Iteration 300/351, loss = 0.2062\n",
            "epoch[3/10] Iteration 0/351, loss = 0.1830\n",
            "epoch[3/10] Iteration 100/351, loss = 0.1789\n",
            "epoch[3/10] Iteration 200/351, loss = 0.1447\n",
            "epoch[3/10] Iteration 300/351, loss = 0.1462\n",
            "epoch[4/10] Iteration 0/351, loss = 0.1060\n",
            "epoch[4/10] Iteration 100/351, loss = 0.1395\n",
            "epoch[4/10] Iteration 200/351, loss = 0.1317\n",
            "epoch[4/10] Iteration 300/351, loss = 0.0884\n",
            "epoch[5/10] Iteration 0/351, loss = 0.0751\n",
            "epoch[5/10] Iteration 100/351, loss = 0.0985\n",
            "epoch[5/10] Iteration 200/351, loss = 0.1098\n",
            "epoch[5/10] Iteration 300/351, loss = 0.0815\n",
            "epoch[6/10] Iteration 0/351, loss = 0.0912\n",
            "epoch[6/10] Iteration 100/351, loss = 0.0863\n",
            "epoch[6/10] Iteration 200/351, loss = 0.0784\n",
            "epoch[6/10] Iteration 300/351, loss = 0.0713\n",
            "epoch[7/10] Iteration 0/351, loss = 0.0744\n",
            "epoch[7/10] Iteration 100/351, loss = 0.0812\n",
            "epoch[7/10] Iteration 200/351, loss = 0.0685\n",
            "epoch[7/10] Iteration 300/351, loss = 0.0661\n",
            "epoch[8/10] Iteration 0/351, loss = 0.0654\n",
            "epoch[8/10] Iteration 100/351, loss = 0.0630\n",
            "epoch[8/10] Iteration 200/351, loss = 0.0663\n",
            "epoch[8/10] Iteration 300/351, loss = 0.0724\n",
            "epoch[9/10] Iteration 0/351, loss = 0.0541\n",
            "epoch[9/10] Iteration 100/351, loss = 0.0643\n",
            "epoch[9/10] Iteration 200/351, loss = 0.0381\n",
            "epoch[9/10] Iteration 300/351, loss = 0.0546\n",
            "epoch[10/10] Iteration 0/351, loss = 0.0493\n",
            "epoch[10/10] Iteration 100/351, loss = 0.0489\n",
            "epoch[10/10] Iteration 200/351, loss = 0.0535\n",
            "epoch[10/10] Iteration 300/351, loss = 0.0602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND8712XqIWLj"
      },
      "source": [
        "# Checker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2MGYo8OkDXd"
      },
      "source": [
        "def checker(x, t, batch_size, model, pad):\n",
        "\n",
        "    data_size = len(x)\n",
        "    max_iters = data_size // batch_size\n",
        "    pad = torch.LongTensor([pad])\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      correct_num = 0\n",
        "      for iters in range(max_iters):\n",
        "        batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
        "        batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
        "\n",
        "        start_id = batch_t[0,0]\n",
        "        correct = batch_t[:,1:]\n",
        "\n",
        "        predict = model.generate(batch_x, start_id, correct.shape[1], pad)\n",
        "        predict = predict[:,1:]\n",
        "\n",
        "        correct_num += (predict == correct).sum()\n",
        "        \n",
        "    return correct_num"
      ],
      "execution_count": 731,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VCFvSrXIYzb"
      },
      "source": [
        "# Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HpiowyN2Rfk",
        "outputId": "33e45944-114e-477e-86fc-fe8967aafddf"
      },
      "source": [
        "correct_num = checker(x_train, t_train, batch_size, model, pad)\n",
        "acc = float(correct_num) / (t_train.shape[0] * (t_train.shape[1] - 1))\n",
        "print('test accuracy %.3f%%' % (acc * 100))\n",
        "\n",
        "correct_num = checker(x_test, t_test, batch_size, model, pad)\n",
        "acc = float(correct_num) / (t_test.shape[0] * (t_test.shape[1] - 1))\n",
        "print('test accuracy %.3f%%' % (acc * 100))"
      ],
      "execution_count": 732,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy 99.082%\n",
            "test accuracy 99.036%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-uBPml1IbM9"
      },
      "source": [
        "# Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgvyoX6mCUGv",
        "outputId": "c539b210-fab8-4aa9-dc83-dfb659cf0c07"
      },
      "source": [
        "for i in range(10):\n",
        "  idx = [np.random.randint(0, len(x_test))]\n",
        "\n",
        "  question = x_test[idx]\n",
        "  correct = t_test[idx]\n",
        "  pad = torch.LongTensor([pad])\n",
        "\n",
        "  correct = correct.flatten()\n",
        "  # 머릿글자\n",
        "  start_id = correct[0]\n",
        "\n",
        "  correct = correct[1:]\n",
        "  with torch.no_grad():\n",
        "    predict  = model.generate(question, start_id, len(correct), pad)\n",
        "  predict = predict[:,1:]\n",
        "\n",
        "  # 문자열로 변환\n",
        "  question = [id_to_char[int(c)] for c in question.flatten()]\n",
        "  correct = [id_to_char[int(c)] for c in correct.flatten()]\n",
        "  predict = [id_to_char[int(c)] for c in predict.flatten()]\n",
        "\n",
        "  print(f'question {i+1} : ', ' '.join(question))\n",
        "  print(f'correct {i+1}  : ', ' '.join(correct))\n",
        "  print(f'predict {i+1}  : ', ' '.join(predict))\n",
        "  print()"
      ],
      "execution_count": 736,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "question 1 :  N o v   2 7 ,   1 9 8 3                                  \n",
            "correct 1  :  1 9 8 3 - 1 1 - 2 7\n",
            "predict 1  :  1 9 8 3 - 1 1 - 2 7\n",
            "\n",
            "question 2 :  9 / 3 0 / 0 8                                            \n",
            "correct 2  :  2 0 0 8 - 0 9 - 3 0\n",
            "predict 2  :  2 0 0 8 - 0 9 - 3 0\n",
            "\n",
            "question 3 :  4 / 1 4 / 8 8                                            \n",
            "correct 3  :  1 9 8 8 - 0 4 - 1 4\n",
            "predict 3  :  1 9 8 8 - 0 4 - 1 4\n",
            "\n",
            "question 4 :  T U E S D A Y ,   J A N U A R Y   1 9 ,   1 9 9 9        \n",
            "correct 4  :  1 9 9 9 - 0 1 - 1 9\n",
            "predict 4  :  1 9 9 9 - 0 1 - 1 9\n",
            "\n",
            "question 5 :  1 0 / 7 / 9 8                                            \n",
            "correct 5  :  1 9 9 8 - 1 0 - 0 7\n",
            "predict 5  :  1 9 9 8 - 1 0 - 0 7\n",
            "\n",
            "question 6 :  a u g   2 7 ,   1 9 7 6                                  \n",
            "correct 6  :  1 9 7 6 - 0 8 - 2 7\n",
            "predict 6  :  1 9 7 6 - 0 8 - 2 7\n",
            "\n",
            "question 7 :  S u n d a y ,   S e p t e m b e r   1 4 ,   2 0 0 8      \n",
            "correct 7  :  2 0 0 8 - 0 9 - 1 4\n",
            "predict 7  :  2 0 0 8 - 0 9 - 1 4\n",
            "\n",
            "question 8 :  m a y   1 2 ,   1 9 9 8                                  \n",
            "correct 8  :  1 9 9 8 - 0 5 - 1 2\n",
            "predict 8  :  1 9 9 8 - 0 5 - 1 2\n",
            "\n",
            "question 9 :  1 0 / 9 / 9 1                                            \n",
            "correct 9  :  1 9 9 1 - 1 0 - 0 9\n",
            "predict 9  :  1 9 9 1 - 1 0 - 0 9\n",
            "\n",
            "question 10 :  T u e s d a y ,   A p r i l   2 1 ,   1 9 9 2            \n",
            "correct 10  :  1 9 9 2 - 0 4 - 2 1\n",
            "predict 10  :  1 9 9 2 - 0 4 - 2 1\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}