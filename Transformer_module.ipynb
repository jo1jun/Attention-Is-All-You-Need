{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer_module.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1KvH4Tc4UzR5YryjjzgjJL5JxiDBi-mjb",
      "authorship_tag": "ABX9TyOL3/M8oYiq4aBSeW6HWuck",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jo1jun/Transformer/blob/main/Transformer_module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYBSRl95FuQM"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR_upKGm3aWx"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 기존과 달리 device, dtype 전부 떼어내야 작동. 추측컨데, 내부적으로 구현이 되어있는 듯 하다.\n",
        "# document 에 parameter 에 device 를 받는다고 나와있는데 바뀐듯 하다. 학습속도가 기존보다 느린데 알아보자.\n",
        "# TODO : device 관련 내부 구현 여부 확인"
      ],
      "execution_count": 742,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf7LgzJyGSJ-"
      },
      "source": [
        "# Token & Positional Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnK60PP6w1nr"
      },
      "source": [
        "class TokPosEmbedding(nn.Module):\n",
        "  def __init__(self, input_dim, d_model, dropout_ratio):\n",
        "    super().__init__()\n",
        "    self.tokEmbedding = nn.Embedding(input_dim, d_model)\n",
        "    self.posEmbedding = nn.Embedding(input_dim, d_model) # 위치 임베딩을 고정 함수가 아니라 학습하는 형태로 구현.\n",
        "    self.d_model = d_model\n",
        "    self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "  def forward(self, src):\n",
        "    batch_size = src.shape[0]\n",
        "    src_len = src.shape[1]\n",
        "\n",
        "    pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1) # 0 ~ src_len 등차 수열값 을 bactch 한개와 동일한 shape으로 생성\n",
        "    \n",
        "    # pos: [batch_size, src_len]\n",
        "\n",
        "    src = self.dropout((self.tokEmbedding(src) * np.sqrt(self.d_model)) + self.posEmbedding(pos))\n",
        "\n",
        "    # src: [batch_size, src_len, d_model]\n",
        "\n",
        "    return src"
      ],
      "execution_count": 743,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72qVz_GlGnIK"
      },
      "source": [
        "# Transformer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx_loYBXxoG7"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, d_model, n_layers, nhead, ff_dim, dropout_ratio):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encEmbedding = TokPosEmbedding(input_dim, d_model, dropout_ratio)                # 외부에서 embedding\n",
        "        self.encoderLayer = nn.TransformerEncoderLayer(d_model, nhead, ff_dim, dropout_ratio) # 구현되어있는 module 사용\n",
        "        self.encoder = nn.TransformerEncoder(self.encoderLayer, n_layers)                     # 구현되어있는 module 사용\n",
        "        self.decEmbedding = TokPosEmbedding(output_dim, d_model, dropout_ratio)               # 외부에서 embedding\n",
        "        self.decoderLayer = nn.TransformerDecoderLayer(d_model, nhead, ff_dim, dropout_ratio) # 구현되어있는 module 사용\n",
        "        self.decoder = nn.TransformerDecoder(self.decoderLayer, n_layers)                     # 구현되어있는 module 사용\n",
        "        self.linear = nn.Linear(d_model, output_dim)                                          # 외부에서 마지막 fc-layer\n",
        "\n",
        "    def make_pad_mask(self, src, pad):\n",
        "\n",
        "        # src: [batch_size, src_len]\n",
        "\n",
        "        # pad mask\n",
        "        src_mask = (src.data.eq(pad))\n",
        "\n",
        "        # src_mask: [batch_size, src_len]\n",
        "        return src_mask\n",
        "\n",
        "    def forward(self, src, tgt, pad):\n",
        "        \n",
        "        # src: [batch_size, src_len]\n",
        "        # tgt: [batch_size, tgt_len]\n",
        "\n",
        "        src_pad_mask = self.make_pad_mask(src, pad)\n",
        "        tgt_pad_mask = self.make_pad_mask(tgt, pad)\n",
        "        # chitting 방지 mask 의 경우, 아래와 같이 이미 구현되어있다. 기존과 mask 값이 다르므로 이미 구현된 것을 사용하면 된다.\n",
        "        tgt_sub_mask = nn.Transformer.generate_square_subsequent_mask(self, sz=tgt.shape[1])\n",
        "\n",
        "        # src_pad_mask: [batch_size, src_len]\n",
        "        # tgt_pad_mask: [batch_size, tgt_len]\n",
        "        # tgt_sub_mask: [tgt_len, tgt_len]\n",
        "\n",
        "        src = self.encEmbedding(src)\n",
        "        tgt = self.decEmbedding(tgt)\n",
        "\n",
        "        # 기존과 달리 input, output 의 dim 0, 1 이 바뀌어 있다.\n",
        "        enc_src = self.encoder(src.transpose(0,1), src_key_padding_mask=src_pad_mask) \n",
        "\n",
        "        # enc_src: [src_len, batch_size, d_model]\n",
        "\n",
        "        output = self.decoder(tgt.transpose(0,1), enc_src, tgt_sub_mask, None, tgt_pad_mask, src_pad_mask)\n",
        "\n",
        "        # output: [tgt_len, batch_size, d_model]\n",
        "\n",
        "        output = self.linear(output.transpose(0, 1))\n",
        "\n",
        "        # output: [batch_size, tgt_len, output_dim]\n",
        "\n",
        "        return output\n",
        "\n",
        "    def generate(self, src, start_id, sample_size, pad):\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "\n",
        "        src_pad_mask = self.make_pad_mask(src, pad)\n",
        "\n",
        "        src = self.encEmbedding(src)\n",
        "\n",
        "        enc_src = self.encoder(src.transpose(0,1), src_key_padding_mask=src_pad_mask)\n",
        "      \n",
        "        sampled_tensor = torch.LongTensor([start_id]).unsqueeze(0).repeat(batch_size, 1)\n",
        "        for _ in range(sample_size):\n",
        "\n",
        "          tgt_pad_mask = self.make_pad_mask(sampled_tensor, pad)\n",
        "          tgt = self.decEmbedding(sampled_tensor)\n",
        "          \n",
        "          # generate 할 때는 하나씩 단어를 생성하므로 tgt_sub_mask 의미 x\n",
        "          output = self.decoder(tgt.transpose(0,1), enc_src, None, None, tgt_pad_mask, src_pad_mask)\n",
        "          output = self.linear(output.transpose(0,1))\n",
        "\n",
        "          pred_token = output.argmax(2)[:,-1].unsqueeze(1)\n",
        "\n",
        "          sampled_tensor = torch.cat((sampled_tensor, pred_token), 1) # pred sentence 에 concat\n",
        "\n",
        "        return sampled_tensor"
      ],
      "execution_count": 744,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1Wt3T1sIOLw"
      },
      "source": [
        "# Date format Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31OPk52Y2DOS",
        "outputId": "9255aed8-937b-4a80-b6ac-f082855d2201"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 745,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTmbqE0665fq",
        "outputId": "1c3d8c74-5d88-42cf-a67f-1f246b183f5b"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/dataset')\n",
        "import sequence\n",
        "\n",
        "# google mount 한 뒤 '/content/drive/MyDrive/' 에 dataset 저장 후 실행.\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = sequence.load_data('date.txt')\n",
        "# char -> id & id -> char dictionary\n",
        "char_to_id, id_to_char = sequence.get_vocab()\n",
        "\n",
        "print(x_train.shape)\n",
        "print(t_train.shape)\n",
        "print(x_test.shape)\n",
        "print(t_test.shape)\n",
        "print()\n",
        "\n",
        "# 이미 id 화 되어있다.\n",
        "print('question(id) : ', x_train[0])\n",
        "print('correct(id)  : ',t_train[0])\n",
        "print()\n",
        "\n",
        "# sequence 확인 # ' ' : pad, '_' : start_char\n",
        "print('question(char) : ', ' '.join([id_to_char[int(c)] for c in x_train[0]]))\n",
        "print('correct(char)  : ', ' '.join([id_to_char[int(c)] for c in t_train[0]]))\n",
        "\n",
        "vocab_size = len(char_to_id)\n",
        "x_train = torch.LongTensor(x_train)\n",
        "t_train = torch.LongTensor(t_train)\n",
        "x_test = torch.LongTensor(x_test)\n",
        "t_test = torch.LongTensor(t_test)\n",
        "pad = 7 # pad token"
      ],
      "execution_count": 746,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(45000, 29)\n",
            "(45000, 11)\n",
            "(5000, 29)\n",
            "(5000, 11)\n",
            "\n",
            "question(id) :  [ 8 22  9 22  9  8  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
            "  7  7  7  7  7]\n",
            "correct(id)  :  [14 11 12  9  8 15 16  8 15 16  9]\n",
            "\n",
            "question(char) :  2 / 7 / 7 2                                              \n",
            "correct(char)  :  _ 1 9 7 2 - 0 2 - 0 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRwkTDN0IQKk"
      },
      "source": [
        "# hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISwDWr4C5djP"
      },
      "source": [
        "batch_size = 128\n",
        "epoch = 10\n",
        "input_dim = output_dim = vocab_size\n",
        "d_model = 32\n",
        "n_layers = 1\n",
        "nhead = 2\n",
        "ff_dim = 1024\n",
        "dropout_ratio = 0.1\n",
        "learning_rate = 0.0025"
      ],
      "execution_count": 747,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9nRECFb-Otd"
      },
      "source": [
        "model = Transformer(input_dim, output_dim, d_model, n_layers, nhead, ff_dim, dropout_ratio)"
      ],
      "execution_count": 748,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqnMGy1W2LbR"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 749,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7OpyjK1ITeB"
      },
      "source": [
        "# Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ILurmyh97dA"
      },
      "source": [
        "def trainer(x, t, max_epoch, batch_size, model, optimizer, pad):\n",
        "\n",
        "    data_size = len(x)\n",
        "    max_iters = data_size // batch_size\n",
        "    pad = torch.LongTensor([pad])\n",
        "\n",
        "    model.train()\n",
        "    for e in range(max_epoch):\n",
        "        for iters in range(max_iters):\n",
        "            batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
        "            batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
        "\n",
        "            # correct 값의 마지막 원소 배제 (end token 없음. 마지막 원소 다음 token 학습할 필요 x)\n",
        "            scores = model(batch_x, batch_t[:, :-1], pad)\n",
        "\n",
        "            scores_dim = scores.shape[-1]\n",
        "\n",
        "            scores = scores.reshape(-1, scores_dim)\n",
        "            \n",
        "            # correct 값의 첫 원소 배제\n",
        "            batch_t = batch_t[:, 1:].reshape(-1)\n",
        "\n",
        "            # scores  : [batch_size * tgt_len - 1, output_dim]\n",
        "            # batch_t : [batch_size * tgt_len - 1]\n",
        "\n",
        "            loss = criterion(scores, batch_t)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0) # gradient clippling\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            if iters % 100 == 0:\n",
        "                print('epoch[%d/%d] Iteration %d/%d, loss = %.4f' % (e+1, max_epoch, iters, max_iters, loss.item()))"
      ],
      "execution_count": 750,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZyw77ZvIUUb"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGHsfmXo2N23",
        "outputId": "2bb02679-c0c1-46bc-9891-2ef143cc5fc1"
      },
      "source": [
        "trainer(x_train, t_train, epoch, batch_size, model, optimizer, pad)"
      ],
      "execution_count": 751,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch[1/1] Iteration 0/351, loss = 4.1073\n",
            "epoch[1/1] Iteration 100/351, loss = 0.9447\n",
            "epoch[1/1] Iteration 200/351, loss = 0.6229\n",
            "epoch[1/1] Iteration 300/351, loss = 0.4225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND8712XqIWLj"
      },
      "source": [
        "# Checker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2MGYo8OkDXd"
      },
      "source": [
        "def checker(x, t, batch_size, model, pad):\n",
        "\n",
        "    data_size = len(x)\n",
        "    max_iters = data_size // batch_size\n",
        "    pad = torch.LongTensor([pad])\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      correct_num = 0\n",
        "      for iters in range(max_iters):\n",
        "        batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
        "        batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
        "\n",
        "        start_id = batch_t[0,0]\n",
        "        correct = batch_t[:,1:]\n",
        "\n",
        "        predict = model.generate(batch_x, start_id, correct.shape[1], pad)\n",
        "        predict = predict[:,1:]\n",
        "\n",
        "        correct_num += (predict == correct).sum()\n",
        "        \n",
        "    return correct_num"
      ],
      "execution_count": 752,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VCFvSrXIYzb"
      },
      "source": [
        "# Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "8HpiowyN2Rfk",
        "outputId": "7b51153e-a249-4e6a-8380-5009b5db24b3"
      },
      "source": [
        "correct_num = checker(x_train, t_train, batch_size, model, pad)\n",
        "acc = float(correct_num) / (t_train.shape[0] * (t_train.shape[1] - 1))\n",
        "print('train accuracy %.3f%%' % (acc * 100))\n",
        "\n",
        "correct_num = checker(x_test, t_test, batch_size, model, pad)\n",
        "acc = float(correct_num) / (t_test.shape[0] * (t_test.shape[1] - 1))\n",
        "print('test accuracy %.3f%%' % (acc * 100))"
      ],
      "execution_count": 753,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-753-cffc88cac1f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorrect_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_num\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train accuracy %.3f%%'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcorrect_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-752-8bcb31bd08a9>\u001b[0m in \u001b[0;36mchecker\u001b[0;34m(x, t, batch_size, model, pad)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-744-e920a8c84fa8>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, src, start_id, sample_size, pad)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m           \u001b[0mtgt_pad_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_pad_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m           \u001b[0mtgt_sub_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_square_subsequent_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m           \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'tgt' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-uBPml1IbM9"
      },
      "source": [
        "# Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgvyoX6mCUGv"
      },
      "source": [
        "for i in range(10):\n",
        "  idx = [np.random.randint(0, len(x_test))]\n",
        "\n",
        "  question = x_test[idx]\n",
        "  correct = t_test[idx]\n",
        "  pad = torch.LongTensor([pad])\n",
        "\n",
        "  correct = correct.flatten()\n",
        "  # 머릿글자\n",
        "  start_id = correct[0]\n",
        "\n",
        "  correct = correct[1:]\n",
        "  with torch.no_grad():\n",
        "    predict  = model.generate(question, start_id, len(correct), pad)\n",
        "  predict = predict[:,1:]\n",
        "\n",
        "  # 문자열로 변환\n",
        "  question = [id_to_char[int(c)] for c in question.flatten()]\n",
        "  correct = [id_to_char[int(c)] for c in correct.flatten()]\n",
        "  predict = [id_to_char[int(c)] for c in predict.flatten()]\n",
        "\n",
        "  print(f'question {i+1} : ', ' '.join(question))\n",
        "  print(f'correct {i+1}  : ', ' '.join(correct))\n",
        "  print(f'predict {i+1}  : ', ' '.join(predict))\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}