{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer_module.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1KvH4Tc4UzR5YryjjzgjJL5JxiDBi-mjb",
      "authorship_tag": "ABX9TyOi5roOiN9jSwEgcqqmR9RT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jo1jun/Transformer/blob/main/Transformer_module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYBSRl95FuQM"
      },
      "source": [
        "# Import, device & dtype"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR_upKGm3aWx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "817d24cc-42e0-4eca-f8a3-6be4d7c3ecae"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "dtype = torch.long\n",
        "\n",
        "% pip install einops\n",
        "\n",
        "from einops import rearrange, repeat, reduce\n",
        "# tensor 연산을 간편하게 하기 위해 einops moudule import.\n",
        "# reference & tutorial : http://einops.rocks/pytorch-examples.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting einops\n",
            "  Downloading https://files.pythonhosted.org/packages/5d/a0/9935e030634bf60ecd572c775f64ace82ceddf2f504a5fd3902438f07090/einops-0.3.0-py2.py3-none-any.whl\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf7LgzJyGSJ-"
      },
      "source": [
        "# Token & Positional Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnK60PP6w1nr"
      },
      "source": [
        "class TokPosEmbedding(nn.Module):\n",
        "  def __init__(self, input_dim, d_model, dropout_ratio):\n",
        "    super().__init__()\n",
        "    # input_dim : input 의 vocab 수.\n",
        "    self.tokEmbedding = nn.Embedding(input_dim, d_model)\n",
        "    self.posEmbedding = nn.Embedding(100, d_model) # cos & sin positional encoding 대신, learnable positional embedding 으로 구현. (max length = 100)\n",
        "                                                   # max length : 입력 sequence 의 최대 길이.\n",
        "    self.d_model = d_model\n",
        "    self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "  def forward(self, src):\n",
        "    batch_size = src.shape[0]\n",
        "    src_len = src.shape[1]\n",
        "\n",
        "    # 0 ~ src_len 등차 수열값 을 bactch 한개와 동일한 shape으로 생성 (positional embedding)\n",
        "    pos = torch.arange(0, src_len, dtype=dtype) # pos: [src_len]\n",
        "    pos = repeat(pos, 'l -> b l', b=batch_size).to(device) # pos: [batch_size, src_len]\n",
        "\n",
        "    src = self.dropout((self.tokEmbedding(src) * np.sqrt(self.d_model)) + self.posEmbedding(pos))\n",
        "\n",
        "    # src: [batch_size, src_len, d_model]\n",
        "\n",
        "    return src"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72qVz_GlGnIK"
      },
      "source": [
        "# Transformer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx_loYBXxoG7"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, d_model, n_layers, nhead, ff_dim, dropout_ratio):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encEmbedding = TokPosEmbedding(input_dim, d_model, dropout_ratio)                # 외부에서 embedding\n",
        "        self.encoderLayer = nn.TransformerEncoderLayer(d_model, nhead, ff_dim, dropout_ratio) # 구현되어있는 module 사용\n",
        "        self.encoder = nn.TransformerEncoder(self.encoderLayer, n_layers)                     # 구현되어있는 module 사용\n",
        "        self.decEmbedding = TokPosEmbedding(output_dim, d_model, dropout_ratio)               # 외부에서 embedding\n",
        "        self.decoderLayer = nn.TransformerDecoderLayer(d_model, nhead, ff_dim, dropout_ratio) # 구현되어있는 module 사용\n",
        "        self.decoder = nn.TransformerDecoder(self.decoderLayer, n_layers)                     # 구현되어있는 module 사용\n",
        "        self.linear = nn.Linear(d_model, output_dim)                                          # 외부에서 마지막 fc-layer\n",
        "\n",
        "    def make_pad_mask(self, src, pad):\n",
        "\n",
        "        # src: [batch_size, src_len]\n",
        "\n",
        "        # pad mask\n",
        "        src_mask = (src.data.eq(pad))\n",
        "\n",
        "        # src_mask: [batch_size, src_len]\n",
        "        return src_mask\n",
        "\n",
        "    def forward(self, src, tgt, pad):\n",
        "        \n",
        "        # src: [batch_size, src_len]\n",
        "        # tgt: [batch_size, tgt_len]\n",
        "\n",
        "        src_pad_mask = self.make_pad_mask(src, pad)\n",
        "        tgt_pad_mask = self.make_pad_mask(tgt, pad)\n",
        "        # chitting 방지 mask 의 경우, 아래와 같이 이미 구현되어있다. 기존과 mask 값이 다르므로 이미 구현된 것을 사용하면 된다.\n",
        "        tgt_sub_mask = nn.Transformer.generate_square_subsequent_mask(self, sz=tgt.shape[1]).to(device)\n",
        "\n",
        "        # src_pad_mask: [batch_size, src_len]\n",
        "        # tgt_pad_mask: [batch_size, tgt_len]\n",
        "        # tgt_sub_mask: [tgt_len, tgt_len]\n",
        "\n",
        "        src = self.encEmbedding(src)\n",
        "        tgt = self.decEmbedding(tgt)\n",
        "\n",
        "        # 기존과 달리 input, output 의 dim 0, 1 이 바뀌어 있다.\n",
        "        enc_src = self.encoder(src.transpose(0,1), src_key_padding_mask=src_pad_mask) \n",
        "\n",
        "        # enc_src: [src_len, batch_size, d_model]\n",
        "\n",
        "        output = self.decoder(tgt.transpose(0,1), enc_src, tgt_sub_mask, None, tgt_pad_mask, src_pad_mask)\n",
        "\n",
        "        # output: [tgt_len, batch_size, d_model]\n",
        "\n",
        "        output = self.linear(output.transpose(0, 1))\n",
        "\n",
        "        # output: [batch_size, tgt_len, output_dim]\n",
        "\n",
        "        return output\n",
        "\n",
        "    def generate(self, src, start_id, sample_size, pad):\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "\n",
        "        src_pad_mask = self.make_pad_mask(src, pad)\n",
        "\n",
        "        src = self.encEmbedding(src)\n",
        "\n",
        "        enc_src = self.encoder(src.transpose(0,1), src_key_padding_mask=src_pad_mask)\n",
        "      \n",
        "        sampled_tensor = torch.tensor([start_id], dtype=dtype)\n",
        "        # sampled_tensor: [1]\n",
        "\n",
        "        sampled_tensor = repeat(sampled_tensor, 's -> b s', b=batch_size).to(device)\n",
        "        # sampled_tensor: [batch_size, 1]\n",
        "        for _ in range(sample_size):\n",
        "\n",
        "          tgt_pad_mask = self.make_pad_mask(sampled_tensor, pad)\n",
        "          tgt = self.decEmbedding(sampled_tensor)\n",
        "          \n",
        "          # generate 할 때는 하나씩 단어를 생성하므로 tgt_sub_mask 의미 x\n",
        "          output = self.decoder(tgt.transpose(0,1), enc_src, None, None, tgt_pad_mask, src_pad_mask)\n",
        "          output = self.linear(output.transpose(0,1))\n",
        "\n",
        "          pred_token = output.argmax(2)[:,-1].unsqueeze(1)\n",
        "\n",
        "          sampled_tensor = torch.cat((sampled_tensor, pred_token), 1) # pred sentence 에 concat\n",
        "\n",
        "        return sampled_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1Wt3T1sIOLw"
      },
      "source": [
        "# Date format Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31OPk52Y2DOS",
        "outputId": "4cf6884b-7414-41b3-c40d-40d7691cf2f8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTmbqE0665fq",
        "outputId": "1c859176-b26e-4179-d780-5d215911024a"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/dataset/dateformat')\n",
        "import sequence\n",
        "\n",
        "# google mount 한 뒤 '/content/drive/MyDrive/dataset' 에 dateformat 폴더 저장 후 실행.\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = sequence.load_data('date.txt')\n",
        "# char -> id & id -> char dictionary\n",
        "char_to_id, id_to_char = sequence.get_vocab()\n",
        "\n",
        "print(x_train.shape)\n",
        "print(t_train.shape)\n",
        "print(x_test.shape)\n",
        "print(t_test.shape)\n",
        "print()\n",
        "\n",
        "# 이미 id 화 되어있다.\n",
        "print('question(id) : ', x_train[0])\n",
        "print('correct(id)  : ',t_train[0])\n",
        "print()\n",
        "\n",
        "# sequence 확인 # ' ' : pad, '_' : start_char\n",
        "print('question(char) : ', ' '.join([id_to_char[int(c)] for c in x_train[0]]))\n",
        "print('correct(char)  : ', ' '.join([id_to_char[int(c)] for c in t_train[0]]))\n",
        "\n",
        "vocab_size = len(char_to_id)\n",
        "x_train = torch.tensor(x_train, dtype=dtype)\n",
        "t_train = torch.tensor(t_train, dtype=dtype)\n",
        "x_test = torch.tensor(x_test, dtype=dtype)\n",
        "t_test = torch.tensor(t_test, dtype=dtype)\n",
        "pad = 7 # pad token"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(45000, 29)\n",
            "(45000, 11)\n",
            "(5000, 29)\n",
            "(5000, 11)\n",
            "\n",
            "question(id) :  [ 8 22  9 22  9  8  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
            "  7  7  7  7  7]\n",
            "correct(id)  :  [14 11 12  9  8 15 16  8 15 16  9]\n",
            "\n",
            "question(char) :  2 / 7 / 7 2                                              \n",
            "correct(char)  :  _ 1 9 7 2 - 0 2 - 0 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRwkTDN0IQKk"
      },
      "source": [
        "# hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISwDWr4C5djP"
      },
      "source": [
        "batch_size = 128\n",
        "epoch = 20\n",
        "input_dim = output_dim = vocab_size\n",
        "d_model = 32\n",
        "n_layers = 1\n",
        "nhead = 2\n",
        "ff_dim = 1024\n",
        "dropout_ratio = 0.1\n",
        "learning_rate = 0.0025"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9nRECFb-Otd"
      },
      "source": [
        "model = Transformer(input_dim, output_dim, d_model, n_layers, nhead, ff_dim, dropout_ratio)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqnMGy1W2LbR"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v41wbzYFVtcI"
      },
      "source": [
        "# Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMLAnqwZVv8j"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "loader_x_train = DataLoader(x_train, batch_size=batch_size)\n",
        "loader_t_train = DataLoader(t_train, batch_size=batch_size)\n",
        "loader_x_test = DataLoader(x_test, batch_size=batch_size)\n",
        "loader_t_test = DataLoader(t_test, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7OpyjK1ITeB"
      },
      "source": [
        "# Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ILurmyh97dA"
      },
      "source": [
        "def trainer(model, optimizer, epochs, pad):\n",
        "\n",
        "    pad = torch.tensor([pad], dtype=dtype).to(device)\n",
        "\n",
        "    model.train()\n",
        "    model = model.to(device)\n",
        "    for e in range(epochs):\n",
        "        for iters, (batch_x, batch_t) in enumerate(zip(loader_x_train, loader_t_train)):\n",
        "\n",
        "            batch_x = batch_x.to(device)\n",
        "            batch_t = batch_t.to(device)\n",
        "\n",
        "            # correct 값의 마지막 원소 배제 (end token 없음. 마지막 원소 다음 token 학습할 필요 x)\n",
        "            scores = model(batch_x, batch_t[:, :-1], pad)\n",
        "\n",
        "            # scores: [batch_size, tgt_len - 1, output_dim]\n",
        "\n",
        "            scores = rearrange(scores, 'b l d -> (b l) d')\n",
        "\n",
        "            # batch_t: [batch_size, tgt_len]\n",
        "            \n",
        "            # correct 값의 첫 원소 배제\n",
        "            batch_t = rearrange(batch_t[:, 1:], 'b l -> (b l)')\n",
        "\n",
        "            # scores  : [batch_size * tgt_len - 1, output_dim]\n",
        "            # batch_t : [batch_size * tgt_len - 1]\n",
        "\n",
        "            loss = criterion(scores, batch_t)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0) # gradient clippling\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            if iters % 100 == 0:\n",
        "                print('epoch[%d/%d] loss = %.4f' % (e+1, epochs, loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZyw77ZvIUUb"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGHsfmXo2N23",
        "outputId": "918696ef-e987-475e-9d06-126bcae1d5c2"
      },
      "source": [
        "trainer(model, optimizer, epoch, pad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch[1/20] loss = 4.2610\n",
            "epoch[1/20] loss = 0.9519\n",
            "epoch[1/20] loss = 0.6491\n",
            "epoch[1/20] loss = 0.4814\n",
            "epoch[2/20] loss = 0.4297\n",
            "epoch[2/20] loss = 0.3528\n",
            "epoch[2/20] loss = 0.2833\n",
            "epoch[2/20] loss = 0.2240\n",
            "epoch[3/20] loss = 0.2180\n",
            "epoch[3/20] loss = 0.2269\n",
            "epoch[3/20] loss = 0.1697\n",
            "epoch[3/20] loss = 0.1589\n",
            "epoch[4/20] loss = 0.1417\n",
            "epoch[4/20] loss = 0.1569\n",
            "epoch[4/20] loss = 0.1564\n",
            "epoch[4/20] loss = 0.1080\n",
            "epoch[5/20] loss = 0.1201\n",
            "epoch[5/20] loss = 0.1165\n",
            "epoch[5/20] loss = 0.1089\n",
            "epoch[5/20] loss = 0.1020\n",
            "epoch[6/20] loss = 0.0864\n",
            "epoch[6/20] loss = 0.0868\n",
            "epoch[6/20] loss = 0.0885\n",
            "epoch[6/20] loss = 0.0656\n",
            "epoch[7/20] loss = 0.0668\n",
            "epoch[7/20] loss = 0.0690\n",
            "epoch[7/20] loss = 0.0802\n",
            "epoch[7/20] loss = 0.0639\n",
            "epoch[8/20] loss = 0.0513\n",
            "epoch[8/20] loss = 0.0560\n",
            "epoch[8/20] loss = 0.0627\n",
            "epoch[8/20] loss = 0.0661\n",
            "epoch[9/20] loss = 0.0440\n",
            "epoch[9/20] loss = 0.0610\n",
            "epoch[9/20] loss = 0.0636\n",
            "epoch[9/20] loss = 0.0511\n",
            "epoch[10/20] loss = 0.0355\n",
            "epoch[10/20] loss = 0.0418\n",
            "epoch[10/20] loss = 0.0427\n",
            "epoch[10/20] loss = 0.0495\n",
            "epoch[11/20] loss = 0.0285\n",
            "epoch[11/20] loss = 0.0504\n",
            "epoch[11/20] loss = 0.0553\n",
            "epoch[11/20] loss = 0.0416\n",
            "epoch[12/20] loss = 0.0412\n",
            "epoch[12/20] loss = 0.0442\n",
            "epoch[12/20] loss = 0.0502\n",
            "epoch[12/20] loss = 0.0331\n",
            "epoch[13/20] loss = 0.0479\n",
            "epoch[13/20] loss = 0.0324\n",
            "epoch[13/20] loss = 0.0365\n",
            "epoch[13/20] loss = 0.0330\n",
            "epoch[14/20] loss = 0.0392\n",
            "epoch[14/20] loss = 0.0397\n",
            "epoch[14/20] loss = 0.0347\n",
            "epoch[14/20] loss = 0.0399\n",
            "epoch[15/20] loss = 0.0428\n",
            "epoch[15/20] loss = 0.0474\n",
            "epoch[15/20] loss = 0.0366\n",
            "epoch[15/20] loss = 0.0341\n",
            "epoch[16/20] loss = 0.0202\n",
            "epoch[16/20] loss = 0.0309\n",
            "epoch[16/20] loss = 0.0323\n",
            "epoch[16/20] loss = 0.0338\n",
            "epoch[17/20] loss = 0.0310\n",
            "epoch[17/20] loss = 0.0363\n",
            "epoch[17/20] loss = 0.0573\n",
            "epoch[17/20] loss = 0.0270\n",
            "epoch[18/20] loss = 0.0182\n",
            "epoch[18/20] loss = 0.0346\n",
            "epoch[18/20] loss = 0.0307\n",
            "epoch[18/20] loss = 0.0392\n",
            "epoch[19/20] loss = 0.0441\n",
            "epoch[19/20] loss = 0.0396\n",
            "epoch[19/20] loss = 0.0272\n",
            "epoch[19/20] loss = 0.0286\n",
            "epoch[20/20] loss = 0.0392\n",
            "epoch[20/20] loss = 0.0545\n",
            "epoch[20/20] loss = 0.0431\n",
            "epoch[20/20] loss = 0.0328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND8712XqIWLj"
      },
      "source": [
        "# Checker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2MGYo8OkDXd"
      },
      "source": [
        "def checker(loader_x, loader_t, model, pad):\n",
        "\n",
        "    pad = torch.tensor([pad], dtype=dtype).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      correct_num = 0\n",
        "      for iters, (batch_x, batch_t) in enumerate(zip(loader_x, loader_t)):\n",
        "\n",
        "        batch_x = batch_x.to(device)\n",
        "        batch_t = batch_t.to(device)\n",
        "\n",
        "        start_id = batch_t[0,0]\n",
        "        correct = batch_t[:,1:]\n",
        "\n",
        "        predict = model.generate(batch_x, start_id, correct.shape[1], pad)\n",
        "        predict = predict[:,1:]\n",
        "\n",
        "        correct_num += (predict == correct).sum()\n",
        "        \n",
        "    return correct_num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VCFvSrXIYzb"
      },
      "source": [
        "# Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HpiowyN2Rfk",
        "outputId": "890b2849-7b64-484d-9d0b-71ccff951396"
      },
      "source": [
        "correct_num = checker(loader_x_train, loader_t_train, model, pad)\n",
        "acc = float(correct_num) / (t_train.shape[0] * (t_train.shape[1] - 1))\n",
        "print('train accuracy %.3f%%' % (acc * 100))\n",
        "\n",
        "correct_num = checker(loader_x_test, loader_t_test,model, pad)\n",
        "acc = float(correct_num) / (t_test.shape[0] * (t_test.shape[1] - 1))\n",
        "print('test accuracy %.3f%%' % (acc * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train accuracy 99.811%\n",
            "test accuracy 99.820%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-uBPml1IbM9"
      },
      "source": [
        "# Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgvyoX6mCUGv",
        "outputId": "802ae245-6962-432d-b895-ec4ad1de931d"
      },
      "source": [
        "for i in range(10):\n",
        "  idx = [i]\n",
        "\n",
        "  question = x_test[idx].to(device)\n",
        "  correct = t_test[idx].to(device)\n",
        "  pad = torch.tensor([pad], dtype=dtype).to(device)\n",
        "\n",
        "  correct = correct.flatten()\n",
        "  # 머릿글자\n",
        "  start_id = correct[0]\n",
        "\n",
        "  correct = correct[1:]\n",
        "  with torch.no_grad():\n",
        "    predict  = model.generate(question, start_id, len(correct), pad)\n",
        "  predict = predict[:,1:]\n",
        "\n",
        "  # 문자열로 변환\n",
        "  question = [id_to_char[int(c)] for c in question.flatten()]\n",
        "  correct = [id_to_char[int(c)] for c in correct.flatten()]\n",
        "  predict = [id_to_char[int(c)] for c in predict.flatten()]\n",
        "\n",
        "  print(f'question {i+1} : ', ' '.join(question))\n",
        "  print(f'correct {i+1}  : ', ' '.join(correct))\n",
        "  print(f'predict {i+1}  : ', ' '.join(predict))\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "question 1 :  1 0 / 1 5 / 9 4                                          \n",
            "correct 1  :  1 9 9 4 - 1 0 - 1 5\n",
            "predict 1  :  1 9 9 4 - 1 0 - 1 5\n",
            "\n",
            "question 2 :  t h u r s d a y ,   n o v e m b e r   1 3 ,   2 0 0 8    \n",
            "correct 2  :  2 0 0 8 - 1 1 - 1 3\n",
            "predict 2  :  2 0 0 8 - 1 1 - 1 3\n",
            "\n",
            "question 3 :  M a r   2 5 ,   2 0 0 3                                  \n",
            "correct 3  :  2 0 0 3 - 0 3 - 2 5\n",
            "predict 3  :  2 0 0 3 - 0 3 - 2 5\n",
            "\n",
            "question 4 :  T u e s d a y ,   N o v e m b e r   2 2 ,   2 0 1 6      \n",
            "correct 4  :  2 0 1 6 - 1 1 - 2 2\n",
            "predict 4  :  2 0 1 6 - 1 1 - 2 2\n",
            "\n",
            "question 5 :  S a t u r d a y ,   J u l y   1 8 ,   1 9 7 0            \n",
            "correct 5  :  1 9 7 0 - 0 7 - 1 8\n",
            "predict 5  :  1 9 7 0 - 0 7 - 1 8\n",
            "\n",
            "question 6 :  o c t o b e r   6 ,   1 9 9 2                            \n",
            "correct 6  :  1 9 9 2 - 1 0 - 0 6\n",
            "predict 6  :  1 9 9 2 - 1 0 - 0 6\n",
            "\n",
            "question 7 :  8 / 2 3 / 0 8                                            \n",
            "correct 7  :  2 0 0 8 - 0 8 - 2 3\n",
            "predict 7  :  2 0 0 8 - 0 8 - 2 3\n",
            "\n",
            "question 8 :  8 / 3 0 / 0 7                                            \n",
            "correct 8  :  2 0 0 7 - 0 8 - 3 0\n",
            "predict 8  :  2 0 0 7 - 0 8 - 3 0\n",
            "\n",
            "question 9 :  1 0 / 2 8 / 1 3                                          \n",
            "correct 9  :  2 0 1 3 - 1 0 - 2 8\n",
            "predict 9  :  2 0 1 3 - 1 0 - 2 8\n",
            "\n",
            "question 10 :  s u n d a y ,   n o v e m b e r   6 ,   2 0 1 6          \n",
            "correct 10  :  2 0 1 6 - 1 1 - 0 6\n",
            "predict 10  :  2 0 1 6 - 1 1 - 0 6\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}